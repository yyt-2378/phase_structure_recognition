{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from abtem import *\n",
    "from ase.io import read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations on (single) GPU's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing calculations on a (single) GPU is no different than CPU calculations. We just have to set `device = gpu` on the object we wish to use for GPU calculations. The objects currently supporting GPU calculations are:\n",
    "\n",
    "* `Potential`\n",
    "* `PlaneWave`\n",
    "* `Probe`\n",
    "* `SMatrix`\n",
    "\n",
    "For example; to create the potential on the GPU and propagate a scattering matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\anaconda3\\envs\\abTEM_interactive\\lib\\site-packages\\cupy\\fft\\_fft.py:451: UserWarning: cuFFT plan cache is disabled on CUDA 11.1 due to a known bug, so performance may be degraded. The bug is fixed on CUDA 11.2+.\n",
      "  cache = get_plan_cache()\n"
     ]
    }
   ],
   "source": [
    "atoms = read('data/orthogonal_graphene.cif') \n",
    "\n",
    "potential = Potential(atoms, sampling=.03, device='gpu').build()\n",
    "\n",
    "S = SMatrix(expansion_cutoff=32, energy=80e3, device='gpu')\n",
    "\n",
    "S_array = S.multislice(potential, pbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potential and the scattering matrix currently exists on the GPU as CuPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cupy._core.core.ndarray, cupy._core.core.ndarray)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(potential.array), type(S_array.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory intensive calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preffered way of doing GPU calculations is to keep everyting in the GPU's memory. However, since GPU memory can be limited abTEM also supports storing the large objects on the host and loading it on the GPU as needed. This is controlled using the `storage` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = SMatrix(expansion_cutoff=32, energy=80e3, device='gpu', storage='cpu')\n",
    "\n",
    "S_on_cpu = S2.multislice(potential, pbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scattering matrix is in CPU memory, however, the calculation device is the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, 'gpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(S_on_cpu.array), S_on_cpu.calculation_device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abTEM_interactive",
   "language": "python",
   "name": "abtem_interactive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
